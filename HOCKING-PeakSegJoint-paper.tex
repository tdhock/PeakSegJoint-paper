\documentclass{article} % For LaTeX2e
\usepackage{nips15submit_e,times}
\usepackage{tikz}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{hyperref}
\usepackage{url}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{amsmath,amssymb,amsthm}
\newtheorem{proposition}{Proposition}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\Lik}{Lik}
\DeclareMathOperator*{\Peaks}{Peaks}
\DeclareMathOperator*{\Segments}{Segments}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\maximize}{maximize}
\DeclareMathOperator*{\minimize}{minimize}
\newcommand{\sign}{\operatorname{sign}}
\newcommand{\RR}{\mathbb R}
\newcommand{\ZZ}{\mathbb Z}
\newcommand{\NN}{\mathbb N}
\definecolor{noPeaks}{HTML}{F6F4BF}
\definecolor{peakStart}{HTML}{FFAFAF}
\definecolor{peakEnd}{HTML}{FF4C4C}
\definecolor{peaks}{HTML}{A445EE}
\newcommand{\JointHeuristic}{\textsc{JointZoom}}

\title{PeakSegJoint: fast supervised peak detection via joint
  segmentation of multiple count data samples}


\author{
David S.~Hippocampus\thanks{ Use footnote for providing further information
about author (webpage, alternative address)---\emph{not} for acknowledging
funding agencies.} \\
Department of Computer Science\\
Cranberry-Lemon University\\
Pittsburgh, PA 15213 \\
\texttt{hippo@cs.cranberry-lemon.edu} \\
\And
Coauthor \\
Affiliation \\
Address \\
\texttt{email} \\
\AND
Coauthor \\
Affiliation \\
Address \\
\texttt{email} \\
\And
Coauthor \\
Affiliation \\
Address \\
\texttt{email} \\
\And
Coauthor \\
Affiliation \\
Address \\
\texttt{email} \\
(if needed)\\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

%\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

\begin{abstract}
  Joint peak detection is a central problem when comparing samples in
  genomic data analysis, and current algorithms for this task are
  unsupervised and limited to at most 2 sample types. We propose
  PeakSegJoint, a new constrained maximum likelihood segmentation
  model for any number of sample types. To select the number of peaks
  in the segmentation, we propose a new supervised penalty learning
  model. To infer the parameters of these two models, we propose to
  use a discrete optimization heuristic for the segmentation, and
  convex optimization for the penalty learning. In comparisons with
  state-of-the-art peak detection algorithms, PeakSegJoint achieves
  comparable accuracy, faster speeds, and a more interpretable model
  with overlapping peaks that occur in exactly the same positions
  across all samples.
\end{abstract}

\section{Introduction}

\subsection{Peak detection in ChIP-seq data}

Chromatin immunoprecipitation sequencing (ChIP-seq) is a biological
experiment for genome-wide profiling of histone modifications and
transcription factor binding sites, with many experimental and
computational steps \citep{practical}. Briefly, each experiment yields
a set of sequence reads which are aligned to a reference genome, and
then the number of aligned reads are counted at each genomic position
(Figure~\ref{fig:good-bad}). These data can be interpreted using
one of the many available peak detection algorithms
\citep{evaluation2010, rye2010manually, chip-seq-bench}, which each
essentially work as a binary classifier for each genomic position. The
positive class is enriched (peaks) and the negative class is
background noise. Importantly, peaks and background occur in long
contiguous segments across the genome.

TODO: more intro about joint peak detection.

In supervised peak detection, there are $n$ labeled genomic regions,
and each $i\in\{1, \dots, n\}$ has a set of labels $L_i$ (``noPeaks,''
``peaks,'' etc. as in Figures~TODO). These labels define a non-convex
annotation error function
\begin{equation}
  \label{eq:error}
  E[c(\mathbf y_i),  L_i] =
  \text{FP}[c(\mathbf y_i), L_i] +
  \text{FN}[c(\mathbf y_i), L_i]
\end{equation}
which counts the number of false positive (FP) and false negative (FN)
regions, so it takes values in the non-negative integers. The goal of
learning is to find a peak caller~$c$ with minimal error on some test
profiles:
\begin{equation}
  \label{eq:min_error}
  \minimize_c \sum_{i\in\text{test}} E[c(\mathbf y_i),  L_i].
\end{equation}
More specifically, we suppose that the training data and the test data
exhibit the same pattern type.
\section{Related work}

\citet{hierarchical-joint} proposed the ChIPmeta HMM, but it is for a
different kind of data: one sample with both ChIP-seq and ChIP-chip
data.

Several unsupervised models have been proposed for joint analysis of
several different ChIP-seq experiments
\citep{jmosaics,segway,chromhmm}. In these models, the input is one
sample (e.g. brain cells) with different experiments such as H3K4me3
and H3K36me3 profiles. In contrast, our proposed \ref{PeakSegJoint} model
takes as input several samples (e.g. brain and kidney cells) for one
experiment such as H3K4me3.

There are several unsupervised algorithms for jointly analyzing
several samples of the same experiment and cell type. For example, the
JAMM algorithm of \citet{JAMM} can analyze several samples but is
limited to a single cell type. 
%It says that it and DFilter are both ``universal'' for broad and narrow peaks. 
% They used TF bindings sites as positive controls. They say that
% it is better to analyze replicates independantly than to pool
% replicates. TODO: run and compare.
% TODO: run DFilter.
The PePr algorithm of \citet{PePr} can identifying peaks that are
common to samples of a single cell type, or different between samples
of two cell types, but is unsuitable for analysis of two or more cell
types. In contrast, our proposed \ref{PeakSegJoint} method models data from
several samples without limit on the number of cell types.
%describe PePr a method for
%identifying consistent or differential peaks across replicates.
% They applied it to TF data sets, and used visual inspection to test
% (but not train). TODO: run and compare.

\begin{figure}[b!]
  \centering
  \includegraphics[width=\textwidth]{figure-good-bad}
  \vskip -0.5cm
  \caption{Labeled ChIP-seq coverage data for $S=4$ samples (top 4
    panels) with 3 peak models (bottom 3 panels).
    % \colorbox{noPeaks}{noPeaks} means there should be no overlapping
    % peaks, \colorbox{peakStart}{peakStart}/\colorbox{peakEnd}{peakEnd}
    % mean there should be exactly 1 peak start/end somewhere in the
    % region, and \colorbox{peaks}{peaks} means that ) 
    An ideal peak model minimizes the number of incorrect labels
    (false positives are too many peaks and false negatives are not
    enough peaks). The ``good'' model achieves 0 errors but the
    ``better'' model is more interpretable since overlapping peaks in
    different samples always occur in the exact same positions.}
  \label{fig:good-bad}
\end{figure}

\section{Models}

We begin by introducing the single-sample PeakSeg model of
\citet{HOCKING-PeakSeg}, which is the current state-of-the-art peak
detection algorithm in the McGill benchmark data set of
\citet{hocking2014visual}. Then we will discuss extensions of the
PeakSeg model to data sets with multiple samples.

\subsection{PeakSeg: finding the best $0,\dots,p_{\text{max}}$ peaks
  in a single sample}

Given a single sample profile $\mathbf z\in\ZZ_+^B$ of aligned reads
across $B$ bases, and a maximum number of peaks $p_{\text{max}}$, the
PeakSeg model for the mean vector $\mathbf m\in\RR^B$ with $p\in\{0,
\dots, p_{\text{max}}\}$ peaks is
\begin{align}
  \label{PeakSeg}
  \mathbf{\tilde m}^p(\mathbf z)  =
    \argmin_{\mathbf m\in\RR^{B}} &\ \ 
    \text{PoissonLoss}(\mathbf m, \mathbf z) 
    \tag{\textbf{PeakSeg}}
\\
    \text{such that} &\ \  \Peaks(\mathbf m)=p,  \\
     \forall j\in\{1, \dots, B\}, &\ \ P_j(\mathbf m) \in\{0, 1\},
    \label{eq:peak_constraint}
\end{align}
where the Poisson loss function is
\begin{equation}\label{eq:rho}
  \text{PoissonLoss}(\mathbf m, \mathbf y)= \sum_{j=1}^B m_j - y_j \log m_j,
\end{equation} 
the model complexity is the number of peaks
\begin{equation}
  \Peaks(\mathbf m)=(\Segments(\mathbf m)-1)/2,
\end{equation}
which is a function of the number of segments
\begin{equation}
  \Segments(\mathbf m)=1+\sum_{j=2}^B I(m_j \neq m_{j-1}),
\end{equation}
and the peak indicator at base $j$ is
\begin{equation}
  \label{eq:peaks}
  P_j(\mathbf m) = \sum_{k=2}^j \sign( m_{k} - m_{k-1} ),
\end{equation}
with $P_1(\mathbf m)=0$ by convention. Note that the constraint
(\ref{eq:peak_constraint}) means that the peak indicator $P_j(\mathbf
m)\in\{0, 1\}$ can be used to classify each base $j\in\{1,\dots B\}$
as either background noise $P_j(\mathbf m)=0$ or a peak $P_j(\mathbf
m)=1$.

\subsection{A multi-sample model 
  related to the single-sample PeakSeg
  model}

For $S$ sample profiles $\mathbf z_1, \dots, \mathbf z_S\in\ZZ_+^B$
defined on the same $B$ bases, we stack the vectors into a matrix
$\mathbf Z\in\ZZ_+^{B \times S}$. Consider the following model for the
mean matrix $\mathbf M\in\RR^{B\times S}$ which allows each sample to
have either 0 or 1 peaks, with a total of $p\in\{0, \dots, S\}$ peaks:
\begin{align}
  \label{Unconstrained}
  \mathbf{\tilde M}^p(\mathbf Z)  =
  \argmin_{\mathbf M\in\RR^{B\times S}} &\ \ 
  \sum_{s=1}^S 
  \text{PoissonLoss}(\mathbf m_s, \mathbf z_s) 
  \tag{\textbf{Unconstrained}}
  \\
  \text{such that} &\ p = \sum_{s=1}^S \Peaks(\mathbf m_s)
  \label{total_Peaks}
  \\
  &\ \forall s\in\{1, \dots, S\},\, 
  \Peaks(\mathbf m_s)\in\{0, 1\},  
  \label{zero_or_one}
  \\
  &\ \forall s\in\{1, \dots, S\},\, 
  \forall j\in\{1, \dots, B\},\, P_j(\mathbf m_s) \in\{0, 1\}.
  \label{up_down}
\end{align}
This optimization problem is \ref{Unconstrained} in the sense that the
peaks are not required to be in the exact same locations in each of
the $S$ samples. The constraint (\ref{up_down}) is the same constraint
as in \ref{PeakSeg}, which here requires the segment mean $\mathbf
m_s$ of each sample to have alternating changes (up, down, up, down
and not up, up, down). The constraint on the number of peaks per
sample (\ref{zero_or_one}) means that each sample may have either zero
or one peak. Finally, the overall constraint (\ref{total_Peaks}) means
that there is a total of $p$ samples each with exactly 1 peak (not
necessarily with the same start/end positions across samples).

\begin{proposition}
The \ref{Unconstrained} solution in $p$ peaks
can be written in terms of the \ref{PeakSeg} solutions in 0 or 1 peaks:
\begin{equation}
  \label{eq:unconstrained_PeakSeg}
  \mathbf{\tilde M}^p(\mathbf Z) = \left[
    \begin{array}{ccc}
      \mathbf{\tilde m}^{p_1}(\mathbf z_1) & 
      \cdots &
      \mathbf{\tilde m}^{p_S}(\mathbf z_S) 
    \end{array}
  \right],
\end{equation}
for some $p_1,\dots, p_S\in\{0, 1\}$ with $p=\sum_{i=s}^S p_s$.
\end{proposition}

\begin{proof}
  Since the objective function of \ref{Unconstrained} is separable on
  samples $s$, it can be re-written as $p$ \ref{PeakSeg} sub-problems
  each with 1 peak, and $S-p$ trivial sub-problems with 0 peaks.
  % To begin, consider the trivial case with $p=0$ peaks. Clearly, the
  % PeakSegJoint solution is
  % $\mathbf{\tilde M}^p(\mathbf Z) = \left[
  %   \begin{array}{ccc}
  %     \mathbf{\bar z}_1 & 
  %     \cdots &
  %     \mathbf{\bar z}_S 
  %   \end{array}
  % \right]$, where $\mathbf{\bar z}_s$ is the constant mean vector for
  % sample $s$. This is also the PeakSeg model with 0 peaks $\mathbf{\tilde
  %   m}^0(\mathbf z_s)=\mathbf{\bar z}_s$. 
  
  % Now consider the case for $p=1$ peak. There are $S$ possible models,
  % one for each sample $s$. The sample with a peak model
  % $\mathbf{\tilde m}^1(\mathbf z_{s^*})$ is $s^*=\argmin_{s\in
  %   1,\dots, S} \textrm{PoissonLoss}\left[ \mathbf{\tilde m}^1(\mathbf
  %   z_s), \mathbf z_s \right] - \textrm{PoissonLoss}\left[
  %   \mathbf{\tilde m}^0(\mathbf z_s), \mathbf z_s \right]$, and all
  % the other samples $s$ have 0 peaks $\mathbf{\tilde m}^0(\mathbf
  % z_{s})$. This model is clearly optimal since the \ref{Unconstrained} cost
  % function is separable on samples.

  % Consider the case for $p=2$ peaks. By the constraint of either zero
  % or one peak for each sample (\ref{zero_or_one}), and the constraint
  % on the total number of peaks (\ref{total_Peaks}), it is clear that
  % the optimal solution has $p=2$ samples with exactly 1 peak and $S-2$
  % samples with exactly 0 peaks. The samples with peaks are $s^*$ and
  % $\argmin_{s\neq s^*} \textrm{PoissonLoss}\left[ \mathbf{\tilde
  %     m}^1(\mathbf z_s), \mathbf z_s \right] -
  % \textrm{PoissonLoss}\left[ \mathbf{\tilde m}^0(\mathbf z_s), \mathbf
  %   z_s \right]$.

  % The proof for $p>2$ peaks proceeds by induction.
\end{proof}

\subsection{PeakSegJoint: finding the best common peak in $0,\dots, S$
  samples}

\begin{figure}[b!]
  \centering
  \includegraphics[width=\textwidth]{figure-PeakSegJoint}
  \caption{A labeled data set with $S=3$ samples (top 3 panels) and
    the models for $p\in\{0, 1, 2, 3\}$ peaks (bottom 4 panels). The
    \ref{Unconstrained} model does not include the \ref{PeakSegJoint}
    constraint (\ref{joint_constraint}) that overlapping peaks should
    occur in exactly the same positions.}
  \label{fig:PeakSegJoint}
\end{figure}

The 
\ref{PeakSegJoint} model with $p\in\{0, \dots, S\}$ peaks is defined by
starting with the \ref{Unconstrained} multi-sample model, and adding
the constraint that peaks should occur in the exact same positions in
each sample (\ref{joint_constraint}):
\begin{align}
  \label{PeakSegJoint}
  \mathbf{\hat M}^p(\mathbf Z)  =
  \argmin_{\mathbf M\in\RR^{B\times S}} &\ \ 
  \sum_{s=1}^S 
  \text{PoissonLoss}(\mathbf m_s, \mathbf z_s) 
  \tag{\textbf{PeakSegJoint}}
  \\
  \text{such that} &\ p = \sum_{s=1}^S \Peaks(\mathbf m_s)
  \nonumber
  \\
  &\ \forall s\in\{1, \dots, S\},\, 
  \Peaks(\mathbf m_s)\in\{0, 1\},  
  \nonumber
  \\
  &\ \forall s\in\{1, \dots, S\},\,
  \forall j\in\{1, \dots, B\},\, P_j(\mathbf m_s) \in\{0, 1\},
  \label{joint_up_down}
  \\
  &\ \forall s_1\neq s_2\mid
  \nonumber
  \Peaks(\mathbf m_{s_1})=\Peaks(\mathbf  m_{s_2})=1,\,
  \forall j\in\{1, \dots, B\},\\
  &\ \ P_j(\mathbf m_{s_1}) = P_j(\mathbf m_{s_2}).
  \label{joint_constraint}
\end{align}

The 
\ref{PeakSegJoint} model for a data set with $S=3$ samples is shown in
Figure~\ref{fig:PeakSegJoint}.

\subsection{Supervised penalty learning}

In the last section we considered data $\mathbf Z\in\ZZ_+^{B\times S}$
for $S$ samples in a single genomic region with $B$ bases. Now assume
that we have data $\mathbf Z_1,\dots, \mathbf Z_n\in\ZZ_+^{B\times S}$
for $n$ genomic regions, along with annotated region labels
$L_1,\dots, L_n$. 

For each genomic region $i\in\{1,\dots,n\}$ we can compute a sequence
of \ref{PeakSegJoint} models $\mathbf{\hat M}^0(\mathbf Z_i),\dots,
\mathbf{\hat M}^S(\mathbf Z_i)$, but how will we predict which of
these $S+1$ models will be best?
% in terms of the test annotated region labels $L_i$? 
This is the segmentation model selection problem, which we propose to
solve via supervised learning of a penalty function.

First, for a positive penalty constant $\lambda\in\RR_+$, we define
the optimal number of peaks as
\begin{equation}
  \label{eq:optimal_segments}
  p^*(\lambda, \mathbf Z) =
  \argmin_{p\in\{0, \dots, S\}}
  p \lambda + 
  \text{PoissonLoss}\left[
    \mathbf{\hat M}^p(\mathbf Z),
    \mathbf Z
  \right].
\end{equation}
Also suppose that we can compute $d$-dimensional sample-specific
feature vectors $\mathbf x\in\RR^d$ and stack them to obtain feature
matrices $\mathbf X_1,\dots, \mathbf X_n\in\RR^{d\times S}$. We will
learn a function $f:\RR^{d\times S}\rightarrow\RR$ that predicts
region-specific penalty values $f(\mathbf X_i) = \log \lambda_i\in\RR$
for each genomic region $i$. In particular we will learn a weight
vector $\mathbf w\in\RR^d$ in a linear function $f_{\mathbf w}(\mathbf X) =
\mathbf w^\intercal \mathbf X \mathbf 1_S$, where $\mathbf 1_S$ is a
vector of $S$ ones.

For supervision we use the annotated region labels $L_i$ to compute
the annotation error (\ref{eq:error}) and a target interval $\mathbf
y_i = (
    \underline y_i, \overline y_i
)$ of penalty values. We used the algorithm of
\citet{HOCKING-penalties} to compute the exact target interval.
% The
% target interval consists of the lower $\underline y_i$ and upper
% $\overline y_i$ limits of the largest region of the $\log \lambda$
% penalty space that has minimum error (\ref{eq:error}). 
Briefly,
a predicted penalty in the target interval $f(\mathbf
X_i)\in\mathbf y_i$ implies that the
\ref{PeakSegJoint} model with $p^*\left[\exp f(\mathbf X_i), \mathbf
  Z_i\right]$ peaks achieves the minimum number of incorrect labels
$L_i$, among all $S+1$ \ref{PeakSegJoint} models for genomic region $i$.
%  $\exp f(\mathbf X_i)\in \argmin_\lambda
% E\left[ \mathbf P\big( \mathbf{\hat M}^{p^*(\lambda, \mathbf
%     Z)}(\mathbf Z) \big), L_i\right]$ (TODO: should we actually show
% this equation or just use words?).

A target interval $\mathbf y$ is used with the squared hinge loss
$\phi(x)=(x-1)^2 I(x\leq 1)$ to define the surrogate loss
\begin{equation}
  \label{eq:surrogate_loss}
  \ell\left[
    \mathbf y,\,
    \log \hat \lambda
    \right]
    =
    \phi\big[
      \log\hat\lambda - \underline y
    \big]
    +
    \phi\big[
    \overline y - \log\hat\lambda
    \big],
\end{equation}
for a predicted penalty value $\hat \lambda\in\RR_+$. For a weight parameter
$\mathbf w\in\RR^d$, the convex average surrogate loss is
\begin{equation}
  \label{eq:average_surrogate}
  \mathcal L(\mathbf w) =
  \frac 1 n
  \sum_{i=1}^n
  \ell\left[
    \mathbf y_i,\,
     f_{\mathbf w}( \mathbf X_i )
    \right].
\end{equation}
Finally, we add a 1-norm penalty to regularize and encourage a sparse
weight vector, thus obtaining the following convex supervised penalty
learning problem:
\begin{equation}
  \label{argmin_w}
  \mathbf{\hat w}^\gamma = 
  \argmin_{\mathbf w\in\RR^d}
  \mathcal L(\mathbf w) + \gamma ||\mathbf w||_1.
\end{equation}

To predict on test data $\mathbf Z$ with features $\mathbf
X$, we compute the predicted penalty $\hat \lambda = \exp
f_{\mathbf{\hat w}}(\mathbf X)$, the predicted number of
peaks $\hat p = p^*(\hat \lambda, \mathbf Z)$, and finally the
predicted model $\mathbf{\hat M}^{\hat p}(\mathbf Z)$.

\section{Algorithms}

\subsection{Heuristic discrete optimization for joint segmentation}

The \ref{PeakSegJoint} model is defined as the solution to an
optimization problem with a convex objective function and non-convex
constraints. We propose to find an approximate solution using a new
discrete optimization algorithm called
\JointHeuristic~(Algorithm~1). 

Real data sets $\mathbf Z\in\ZZ_+^{B\times S}$ may have a very large
number of data points to segment $B$. Searching every possible peak
start and end point is an $O(B^2)$ operation which would take too much
time. 

The main idea of the \JointHeuristic\ algorithm is to first zoom out
(downsample the data) repeatedly by a factor of $\beta$, obtaining a
new data matrix of size $b\times S$, where $b \ll B$
(line~\ref{zoomout}). Then we solve the \ref{PeakSegJoint} problem for
$p$ peaks via \textsc{GridSearch} (line~\ref{gridsearch}), a
sub-routine that checks all $O(b^2)$ possible peak start and end
positions. Then we zoom in by a factor of $\beta$ (line~\ref{zoomin})
and refine the peak positions in $O(\beta^2)$ time via
\textsc{SearchNearPeak} (line~\ref{searchnear}). After having zoomed
back in to the BinSize=1 level we return the final Peak positions.

\begin{algorithm}[H]
\begin{algorithmic}[1]
  \REQUIRE count data $\mathbf Z\in\ZZ_+^{B\times S}$, number of
  peaks $p\in\{0, \dots, S\}$, zoom factor
  $\beta\in\{2, 3, \dots\}$.
  \STATE $\textrm{BinSize} \gets \textsc{MaxBinSize}(B, \beta)$. \label{zoomout}
  \STATE $\textrm{Peak}, \textrm{Samples} \gets \label{gridsearch}
  \textsc{GridSearch}(\mathbf Z, p, \textrm{BinSize})$.
  \WHILE{$1 < \textrm{BinSize}$}
  \STATE $\textrm{BinSize} \gets \textrm{BinSize} / \beta$. \label{zoomin}
  \STATE $\textrm{Peak} \gets
  \textsc{SearchNearPeak}(\mathbf Z, \textrm{Samples}, \label{searchnear}
  \textrm{BinSize}, \textrm{Peak})$
  \ENDWHILE
  \RETURN Peak.
\caption{\JointHeuristic}
\end{algorithmic}\label{algo}
\end{algorithm}

An example of the algorithm is shown in
Figure~\ref{fig:heuristic-algo}, which has a data size of $B=TODO$
data points to segment. \textsc{MaxBinSize} returns $b=TODO$ data
points to segment, and TODO.

\begin{figure}[b!]
  \centering
  \includegraphics[width=\textwidth]{figure-heuristic-algo}
  \vskip -0.5cm
  \caption{Demonstration of the \JointHeuristic\ segmentation
    algorithm. For a data set with $B=24$ data points and $S=2$
    samples (top 2 panels), the algorithm with zoom factor of
    $\beta=2$ proceeds as follows. First, the Poisson loss and
    feasibility (\ref{joint_up_down}) is computed for all possible
    peak starts and ends at bin size 4. The feasible model with
    minimum Poisson loss is selected, the bin size is decreased to 2,
    and we consider a new set of models around the selected peak
    starts and ends. We continue and return the selected model at bin
    size 1 (shown in green). Interactive figure at
    \url{http://bit.ly/1AA6TgK}}
  \label{fig:heuristic-algo}
\end{figure}

\subsection{Convex optimization for supervised penalty learning}

The convex supervised learning problem (\ref{argmin_w}) can be
computed using gradient-based methods such as FISTA, a Fast Iterative
Shinkage-Thresholding Algorithm \citep{fista}. To apply FISTA, we need
to compute the gradient of the smooth average surrogate loss
\begin{equation}
  \label{eq:average_gradient}
  \nabla \mathcal L(\mathbf w) = 
  \frac 1 n
  \sum_{i=1}^n 
  \nabla \ell \left[
    \mathbf y_i,\,
    f_{\mathbf w}(  \mathbf X_i )
  \right],
\end{equation}
where the gradient of one observation $i$ is
\begin{equation}
  \label{eq:one_gradient}
  \nabla \ell \left[
    \mathbf y_i,\,
    f_{\mathbf w}( \mathbf X_i )
  \right]
  =
  \mathbf X_i \mathbf 1_S
  \left[
    \phi'\big(
    f_{\mathbf w}( \mathbf X_i ) - \underline y_i
    \big)
    -
    \phi'\big(
    \overline y_i - f_{\mathbf w}( \mathbf X_i )
    \big)
  \right],
\end{equation}
and the derivative of the squared hinge loss is $\phi'(x)=2(x-1)I(x\leq 1)$.

For FISTA with constant step size we also need a Lipschitz constant of
$\mathcal L(\mathbf w)$. Following the arguments of
\citet{hingeSquareFISTA}, we derived a Lipschitz constant of
$\sum_{i=1}^n ||\mathbf X_i||_F^2/n$. Finally, we used the
subdifferential stopping criterion of \citet{HOCKING-penalties}.

% An optimality condition for (\ref{argmin_w}) is 
% \begin{equation}
%   \label{eq:optimality}
%   \nabla \mathcal L(\mathbf w) \in \gamma \partial ||\mathbf w||_1.
% \end{equation}

\section{Results}

\subsection{Accuracy of PeakSegJoint on benchmark data sets}

We compared with several unsupervised single-sample and multi-sample
peak callers from the bioinformatics literature. Each algorithm was
trained by using grid search to select the significance threshold
hyperparameter that minimized the train error.

The McGill benchmark data sets that we analyzed contain samples of
several different cell types. However, the multi-sample JAMM and PePr
algorithms are designed for the analysis of several replicates of a
single cell type. So upon recommendation from the authors we ran these
algorithms independently on each cell type.

\begin{figure}[b!]
  \centering
  \includegraphics[width=\textwidth]{figure-test-error-dots.pdf}
  \caption{Test error of peak detectors in the 7 McGill Histone
    benchmark data sets (panels from left to right). Each dot shows
    one of 6 train/test splits, and the black vertical line marks the
    mean of the \ref{PeakSegJoint} model.}
  \label{fig:test-error-dots}
\end{figure}

\subsection{Speed of heuristic PeakSegJoint algorithm}

The \JointHeuristic\ algorithm is orders of magnitude faster than
existing Poisson segmentation algorithms
(Figure~\ref{fig:timings}). For simulated data sets of size
$B\in\{10^1, \dots, 10^6\}$, we compared PeakSegJoint with the
$O(B\log B)$ unconstrained pruned dynamic programming algorithm (pDPA)
of \citet{Segmentor} (R package Segmentor3IsBack), and the $O(B^2)$
constrained dynamic programming algorithm (cDPA) of
\citet{HOCKING-PeakSeg} (R package
PeakSegDP). Figure~\ref{fig:timings} indicates that PeakSegJoint
enjoys the same $O(B \log B)$ asymptotic behavior as the pDPA. However
the \JointHeuristic\ algorithm is faster by at least two orders of
magnitude for the range of data sizes that is typical for real data
($10^2 < B < 10^6$).

These speed differences are magnified when applying these Poisson
segmentation models to real ChIP-seq data sets. For example, the hg19
human genome assembly has about $3\times 10^9$ bases. For the
H3K36me3\_AM\_immune data set, a resolution of about 200 kilobases per
problem was optimal, so running PeakSegJoint on the entire human
genome means solving about 15,000 segmentation problems. PeakSegJoint
takes about 0.1 seconds to solve each of those problems
(Figure~\ref{fig:timings}), meaning a total computation time of about
25 minutes. In contrast, using the pDPA would be orders of magnitude
slower (hours or days of computation).

\begin{figure}[b!]
  \centering
  \input{figure-timings}
  \vskip -0.5cm
  \caption{Timings of three Poisson segmentation algorithms on
    simulated data sets of varying size $B$. The grey shaded area
    represents the range of problem sizes selected in the McGill
    Histone benchmark data sets. }
  \label{fig:timings}
\end{figure}

\section{Discussion}

\section{Conclusions}

Faster.

As accurate as state of the art.

More interpretable (same peaks, several cell types). This was
advantageous in the McGill H3K4me3\_TDH\_immune data set, which
contains 3 cell types: tcell, bcell, and monocyte. The PeakSegJoint
model can be run once on all cell types, and the resulting model
can be easily interpreted to find the differences, since peaks occur
in the exact same locations across samples. In contrast, existing
methods such as JAMM or PePr are less suitable to analyze this data
set since they are limited to modeling only 1 or 2 cell types.

\bibliographystyle{abbrvnat}
\bibliography{refs}

\end{document}
